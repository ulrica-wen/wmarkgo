import streamlit as st
from PIL import Image
import os
dir_path = os.path.split(os.path.realpath(__file__))[0]
import sys
sys.path.append(dir_path)

st.set_page_config(
    page_title="DeepFloyd IF Model Introduction",
    page_icon=":Scroll:",
    layout='wide'
)

st.title('üìú DeepFloyd IF Model Introduction')

st.subheader('Introduction')
st.markdown(
    """
    DeepFloyd IF is a state-of-the-art text-to-image model released by StabilityAI in late April, 2023 that achieves a high degree of photorealism and language understanding. DeepFloyd is built with multiple neural modules (independent neural networks that tackle specific tasks), and generates high-resolution images in a cascading approach. The model is composed of a frozen text encoder and three cascaded pixel diffusion modules: a base model that generates 64x64 pixel image based on the input text prompt and two super-resolution models that generates images with resolution 256x256 pixel and 1024x1024 pixel. All stages of the model utilize a frozen text encoder based on the T5-XXL to extract text embeddings, which are then fed into a UNet architecture enhanced with cross-attention and attention pooling. 
    \n
    As a result, DeepFloyd achieves a zero-shot Frechet Inception Distance (FID) score of 6.66 on the COCO dataset, which outperforms other novel text-to-image models including DALL-E 2 (10.39), Imagen (7.27), and eDiff-I (6.95).

    **The following generation flowchart demonstrates the three-stage process**:
    \n

    - A **text prompt** is passed through the frozen T5-XXL language model to convert into a qualitative text representation
    \n
    - **Stage 1**: A base diffusion model transforms the qualitative text into a 64x64 image. There are three versions of the base model each with different number of parameters: 400M, 900M, and 4.3B. 
    \n
    - **Stage 2**: To upscale the image, two text-conditional super-resolution models are applied to the output of the base model. The first super-resolution model upscales the 64x64 image to 256x256. 
    \n
    - **Stage 3**: The second super-resolution diffusion model is applied and produces a 1024x1024 image.
    """
)

st.info("""
        DeepFloyd Structure
        """,
        icon = "üñºÔ∏è")
st.image(Image.open(dir_path+'/image outcome/DeepFloyd Intro.jpg'))

st.subheader('Key Features')

st.markdown(
    """
    Some key features of DeepFloyd which distincts it from other text-to-image models are as follows:
    \n    
    - Pixel-Based: DeepFloyd operates directly in the pixel space (i.e. on uncompressed images), instead of running the denoising process in the latent space (such as Stable Diffusion)
    \n
    - Strong Text Prompt Understanding: By utilizing the T5-XXL language model as a text encoder, the model incorporates numerous text-image cross attention layers and ensures a better alignment between text prompts and generated images. As a result, DeepFloyd is good at understanding complex prompts and even generating correctly spelled text in images.
    \n
    - High Quality Training Dataset: DeepFloyd was trained on a custom high-quality LAION-dataset consisting of 1.2 billion image-text pairs. This LAION-1.2B dataset is an aesthetic subset obtained from the original LAION-5B dataset through extra cleaning and deduplication. As a result, DeepFloyd is better at generating images with high-frequency details, such as human faces, hands, and animal faces. DeepFloyd also generates more realistic images compared with Midjourney, which tends to generate images that are fantasy-looking. 
    \n
    - Zero-shot Image-to-Image Translations: DeepFloyd is able to modify images by resizing the original input image to 64 pixels, adding noise through forward diffusion, and denoising using backward diffusion with a new prompt. This allows modifying the input image's style, pattern, and details and maintains the source image's basic form without the need for fine-tuning.
    """
)

st.subheader('Some Caveats')

st.markdown(
    """
    Some current caveats of DeepFloyd include the following: 
    \n
    - Similar to other text-to-image models, the images generated by DeepFloyd does not achieve perfect photorealism and has a success rate. There is a probability that a random image generated will not be of high quality.
    \n 
    - DeepFloyd was trained primarily with English captions, therefore it's ability to generate images from other languages is limited. 
    """
)